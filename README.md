# ğŸ¤– Efficient Fine-Tuning of Open-Source LLMS

In this repo, we'll be fine-tuning a GPT-style model using peft, transformers, and bitsandbytes. We'll task fine-tune Mistral-7B-Instruct-v0.2 using QLoRA/LoRA. 


### âš™ï¸The colab link to the code is found and (will also be included in this repo) [here.](https://colab.research.google.com/drive/1528lAqNcDy2K-9rSEBKD_xUGyd5bPRaf?usp=sharing)

### ğŸ«‚The video walkthrough can be found [here.](https://www.loom.com/share/39f6616788ec4f61acfca999417f9102?sid=745ddda3-1a09-4733-9c8c-4e65e2dd5dae)

# âš™ï¸The Build Process ğŸ—ï¸
* Create a Python 3.11 environment
* pip install jupyter
* pip install -r requirements.txt
* Load the model
* Prep the data
* Create the create_prompt function
* Set up PEFT LoRA
* Train the model
* Share the model
